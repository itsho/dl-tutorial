{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ERC-KKA-FC6",
    "colab_type": "text"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "mA0joW1K68Qw",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# Plot ad hoc mnist instances\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "# load (downloaded if needed) the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# plot 4 images as gray scale\n",
    "plt.subplot(221)\n",
    "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "7cVIjYF07gFh",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H_6582N3-pZ3",
    "colab_type": "text"
   },
   "source": [
    "# Single Layer Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "knH0rrEm_ODW",
    "colab_type": "text"
   },
   "source": [
    "## Flatten and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "crDGdDyH-C1A",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "r94WbWQc_L6N",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# flatten 28*28 images to a 784 vector for each image\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')\n",
    "\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "qEzxRPCc_W0J",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bs2oLVn6_jra",
    "colab_type": "text"
   },
   "source": [
    "## One-hot for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "uPdhm3GeBzIG",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "g3qz76UFB063",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aklj7Uv2CAUF",
    "colab_type": "text"
   },
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "I_IjB8aZCCLl",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "v3eaelFdCijj",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
    "\n",
    "# Show training progress\n",
    "plt.plot(history.history['acc'], 'b--')\n",
    "plt.plot(history.history['val_acc'], 'r--')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train Accuracy', 'Test Accuracy'], loc='lower right')\n",
    "plt.show()\n",
    "plt.plot(history.history['loss'], 'b-')\n",
    "plt.plot(history.history['val_loss'], 'r-')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "otrcMpD1HevI",
    "colab_type": "text"
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "5032FWXnHgxm",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "test_idx = 157\n",
    "\n",
    "image = X_test[test_idx]\n",
    "image = image.reshape(28, 28)\n",
    "image = image * 255\n",
    "image = image.astype(np.uint8)\n",
    "plt.imshow(image, cmap=plt.get_cmap('gray'))\n",
    "plt.show()\n",
    "\n",
    "label = y_test[test_idx]\n",
    "print(f\"label: {label}\")\n",
    "\n",
    "prediction = model.predict(X_test[test_idx:test_idx+1])\n",
    "print(f\"prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJZBW5PmbZtB",
    "colab_type": "text"
   },
   "source": [
    "# Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "nWGLAP1Iboyu",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GgvGtsWMb0r6",
    "colab_type": "text"
   },
   "source": [
    "### Training the model on 1/100 of the data but with 100 times the epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "dj1qK79dbusm",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "history = model.fit(X_train[:600], y_train[:600], validation_data=(X_test[:100], y_test[:100]), epochs=100, batch_size=200, verbose=0)\n",
    "\n",
    "# Show training progress\n",
    "plt.plot(history.history['acc'], 'b--')\n",
    "plt.plot(history.history['val_acc'], 'r--')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train Accuracy', 'Test Accuracy'], loc='lower right')\n",
    "plt.show()\n",
    "plt.plot(history.history['loss'], 'b-')\n",
    "plt.plot(history.history['val_loss'], 'r-')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X0HzLycwG3iW",
    "colab_type": "text"
   },
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "zehhDA3yG6YR",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ES6vb2J4HEMD",
    "colab_type": "text"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "R2Its1mbHIuE",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
    "\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "yGRvWrfpHLp3",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1UYwGwfYHfLH",
    "colab_type": "text"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "fGASroKBHgy6",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "w3t44b1BArL3",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
    "\n",
    "# Show training progress\n",
    "plt.plot(history.history['acc'], 'b--')\n",
    "plt.plot(history.history['val_acc'], 'r--')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train Accuracy', 'Test Accuracy'], loc='lower right')\n",
    "plt.show()\n",
    "plt.plot(history.history['loss'], 'b-')\n",
    "plt.plot(history.history['val_loss'], 'r-')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TSRKIXNYDfh0",
    "colab_type": "text"
   },
   "source": [
    "# Larger CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "zz6Dkzm0Dkt0",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HnfOTbOEDzRw"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code",
    "id": "Udu1fj4aDzRy",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
    "\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code",
    "id": "DjKpA4f0DzR1",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oHQCCoe0DzR5"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code",
    "id": "3IOgKPvHDzR6",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(30, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code",
    "id": "FaA8FIL0DzR8",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
    "\n",
    "# Show training progress\n",
    "plt.plot(history.history['acc'], 'b--')\n",
    "plt.plot(history.history['val_acc'], 'r--')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train Accuracy', 'Test Accuracy'], loc='lower right')\n",
    "plt.show()\n",
    "plt.plot(history.history['loss'], 'b-')\n",
    "plt.plot(history.history['val_loss'], 'r-')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Large CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7GabxZEoXGzr",
    "colab_type": "text"
   },
   "source": [
    "# Finetuning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_MXL5QKe1lg",
    "colab_type": "text"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "wFp9TNNJYZE8",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# flip\n",
    "X_train = X_train[:, ::-1, :]\n",
    "X_test = X_test[:, ::-1, :]\n",
    "\n",
    "# plot 4 images as gray scale\n",
    "plt.subplot(221)\n",
    "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
    "# show the plot\n",
    "plt.show()\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "6eBTdqgQfy6O",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
    "\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HI9MtAhgnkP",
    "colab_type": "text"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "HEGSNx8GXJmX",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# update model\n",
    "model.pop()\n",
    "model.pop()\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# freeze layers\n",
    "for layer in model.layers[:-2]:\n",
    "  layer.trainable = False\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "4QajoWY7gWcP",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "history = model.fit(X_train[:600], y_train[:600], validation_data=(X_test, y_test), epochs=100, batch_size=200, verbose=0)\n",
    "\n",
    "# Show training progress\n",
    "plt.plot(history.history['acc'], 'b--')\n",
    "plt.plot(history.history['val_acc'], 'r--')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train Accuracy', 'Test Accuracy'], loc='lower right')\n",
    "plt.show()\n",
    "plt.plot(history.history['loss'], 'b-')\n",
    "plt.plot(history.history['val_loss'], 'r-')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Large CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "MNIST_1.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
